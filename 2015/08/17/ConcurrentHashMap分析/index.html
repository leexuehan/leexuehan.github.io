<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="1EB8XoOl0C"><meta name="google-site-verification" content="K7thEgdLm0UfRWJ5MGdF7sCcjClSzAlxFLPv2Oz5CGM"><title> ConcurrentHashMap分析 · 以梦为码的博客</title><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="ConcurrentHashMap分析 - Leexuehan"><meta name="keywords"><meta name="author" content="Leexuehan"><link rel="short icon" href="/images/favicon.ico"><link rel="stylesheet" href="/css/bubuzou.css"><link rel="search" type="application/opensearchdescription+xml" href="https://leexuehan.github.io/atom.xml" title="以梦为码的博客"><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script></head><body><header><div class="header row"> <a href="/" class="logo-link"><img src="/images/logo.png"></a><ul id="nav_list" class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" data-hover="博文" class="nav-list-link">博文</a></li><li class="nav-list-item"><a href="/archives/" target="_self" data-hover="归档" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/categories/闲聊/" target="_self" data-hover="生活" class="nav-list-link">生活</a></li><li class="nav-list-item"><a href="/categories/技术/" target="_self" data-hover="技术" class="nav-list-link">技术</a></li><li class="nav-list-item"><a href="/about/" target="_self" data-hover="关于" class="nav-list-link">关于</a></li></ul><div class="search"><a id="search_btn" href="#search"></a></div><div id="nav_btn" class="nav-btn"><span></span><span></span><span></span></div></div></header><div class="row scroll-con"><section class="container"><!-- for archive page--><div id="postAr" class="post"><article class="post-block"><h1 class="post-title">ConcurrentHashMap分析</h1><div class="post-info">2015-08-17<p class="visit"><i data-identity="2015/08/17/ConcurrentHashMap分析/" class="article-timer"></i><span>次访问</span></p></div><div class="post-content"><h3 id="前面的话"><a href="#前面的话" class="headerlink" title="前面的话"></a>前面的话</h3><p>这几天在看 Java.util.concurrent 包里的各种类，关于这个包的关系图，网上有一张很清晰的图如下：</p>
<p><img src="http://i.imgur.com/iWxDC8g.png" alt></p>
<p>打算在接下来的一周时间里，将 collections 里面的 BlockingQueue 和 ConcurrentHashMap 以及 executor 重点看完，将其核心源码弄明白，如果之后还有时间的话，会写一些例子来使用它们。</p>
<p>这一篇主要讲 ConcurrentHashMap。</p>
<h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><h3 id="锁分段"><a href="#锁分段" class="headerlink" title="锁分段"></a>锁分段</h3><p>因为多线程环境下，HashMap 会有线程安全问题， Hashtable 虽然是线程安全的，但是它使用 synchronized 来保证线程安全，但这样一来，在大规模的线程访问的情况下就会出现效率低下的问题，因为如果有一个线程拥有这把锁，则其他的线程只能等待。</p>
<p>在这种情况下，软件大牛们想出了一个解决办法：<strong>锁分段</strong>。</p>
<p>什么是锁分段？</p>
<p>Hashtable 容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问 Hashtable 的线程必须竞争同一把锁。设想一下，如果容器有多把锁，则每一把锁用于锁住容器其中的一部分数据，那么当多线程访问容器里不同的数据段的数据时，线程之间不会存在锁竞争，从而有效地提高并发访问率。这就是<strong>锁分段技术</strong>。</p>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p><img src="http://i.imgur.com/QHn33G7.png" alt></p>
<p>上图就是 ConcurrentHashMap 的大致结构。</p>
<p>可以看出来，它是由 一个私有的Segment数组和 HashEntry 数组结构组成。而Segment是一种可重入锁 ReentrantLock。</p>
<pre><code> static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {
    ...
}
</code></pre><p>Segment的结构与HashMap类似，是一种数据和链表结构，一个Segment 里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据修改时，必须首先获取它对应的Segment锁。</p>
<p>结构如下：</p>
<p><img src="http://i.imgur.com/rS67Ipe.png" alt></p>
<p>HashEntry 用于存储键值对数据。</p>
<h3 id="ConcurrentHashMap-的初始化"><a href="#ConcurrentHashMap-的初始化" class="headerlink" title="ConcurrentHashMap 的初始化"></a>ConcurrentHashMap 的初始化</h3><p>ConcurrentHashMap初始化方法是通过initialCapacity，loadFactor, concurrencyLevel几个参数来初始化segments数组，段偏移量segmentShift，段掩码segmentMask和每个segment里的HashEntry数组 。</p>
<p>以下是其初始化的源代码</p>
<pre><code>public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)
        throw new IllegalArgumentException();

    if (concurrencyLevel &gt; MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;

    // Find power-of-two sizes best matching arguments
    int sshift = 0;
    int ssize = 1;
    while (ssize &lt; concurrencyLevel) {
        ++sshift;
        ssize &lt;&lt;= 1;
    }
    segmentShift = 32 - sshift;
    segmentMask = ssize - 1;
    this.segments = Segment.newArray(ssize);

    if (initialCapacity &gt; MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    int c = initialCapacity / ssize;
    if (c * ssize &lt; initialCapacity)
        ++c;
    int cap = 1;
    while (cap &lt; c)
        cap &lt;&lt;= 1;

    for (int i = 0; i &lt; this.segments.length; ++i)
        this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor);
}
</code></pre><p>代码解析：</p>
<p>1.初始化Segment数组的长度</p>
<p>由上面的代码可知segments数组的长度ssize通过concurrencyLevel计算得出。为了能通过按位与的哈希算法来定位segments数组的索引，必须保证segments数组的长度是2的N次方（power-of-two size），所以必须计算出一个是大于或等于concurrencyLevel的最小的2的N次方值来作为segments数组的长度。假如concurrencyLevel等于14，15或16，ssize都会等于16，即容器里锁的个数也是16。注意concurrencyLevel的最大大小是65535，意味着segments数组的长度最大为65536，对应的二进制是16位。</p>
<p>2.初始化segmentShift和segmentMask。</p>
<p>这两个全局变量在定位segment时的哈希算法里需要使用，sshift等于ssize从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与hash运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用32是因为ConcurrentHashMap里的hash()方法输出的最大数是32位的，后面的测试中我们可以看到这点。segmentMask是哈希运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是1。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。</p>
<p>3.初始化每个Segment。输入参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个segment。</p>
<pre><code>if (initialCapacity &gt; MAXIMUM_CAPACITY)
    initialCapacity = MAXIMUM_CAPACITY;
int c = initialCapacity / ssize;
if (c * ssize &lt; initialCapacity)
    ++c;
int cap = 1;
while (cap &lt; c)
    cap &lt;&lt;= 1;

for (int i = 0; i &lt; this.segments.length; ++i)
    this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor);
</code></pre><p>上面代码中的变量cap就是segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以cap不是1，就是2的N次方。segment的容量threshold＝(int)cap*loadFactor，默认情况下initialCapacity等于16，loadfactor等于0.75，通过运算cap等于1，threshold等于零。</p>
<pre><code>Segment(int initialCapacity, float lf) {
    loadFactor = lf;
    setTable(HashEntry.&lt;K,V&gt;newArray(initialCapacity));
}
</code></pre><p>这是 Segment 的构造函数。其中 newArray 的实现代码：</p>
<pre><code>static final &lt;K,V&gt; HashEntry&lt;K,V&gt;[] newArray(int i) {
    return new HashEntry[i];
}
</code></pre><p>setTable的实现代码：</p>
<pre><code> void setTable(HashEntry&lt;K,V&gt;[] newTable) {
    threshold = (int)(newTable.length * loadFactor);
    table = newTable;
}
</code></pre><p>至此，初始化已经完成。</p>
<h3 id="ConcurrentHashMap-的重要操作"><a href="#ConcurrentHashMap-的重要操作" class="headerlink" title="ConcurrentHashMap 的重要操作"></a>ConcurrentHashMap 的重要操作</h3><h4 id="get-操作"><a href="#get-操作" class="headerlink" title="get 操作"></a>get 操作</h4><pre><code>public V get(Object key) {
    int hash = hash(key.hashCode());
    return segmentFor(hash).get(key, hash);
}
</code></pre><h4 id="put-操作"><a href="#put-操作" class="headerlink" title="put 操作"></a>put 操作</h4><pre><code>public V put(K key, V value) {
    if (value == null)
        throw new NullPointerException();
    int hash = hash(key.hashCode());
    return segmentFor(hash).put(key, hash, value, false);
}
</code></pre><h4 id="remove-操作"><a href="#remove-操作" class="headerlink" title="remove 操作"></a>remove 操作</h4><pre><code> public V remove(Object key) {
int hash = hash(key.hashCode());
    return segmentFor(hash).remove(key, hash, null);
}
</code></pre><p>以上三种操作有一个共同点就是：无论是增、删、查，最终都归结为 segment的相应操作，且都用到了segmentFor 这个函数 。关于Segment 后面会有介绍，此处先不表。</p>
<p>先简要说一下 segmentFor 这个函数。</p>
<pre><code>final Segment&lt;K,V&gt; segmentFor(int hash) {  
    return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];  
} 
</code></pre><p>这个函数用了位操作来确定Segment，根据传入的hash值向右无符号右移segmentShift位，然后和segmentMask进行与操作，结合我们之前说的segmentShift和segmentMask的值，就可以得出以下结论：假设Segment的数量是2的n次方，根据元素的hash值的高n位就可以确定元素到底在哪一个Segment中。</p>
<h4 id="size-操作"><a href="#size-操作" class="headerlink" title="size 操作"></a>size 操作</h4><p>size 操作有点不同，如果我们要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和。</p>
<p>Segment里的全局变量count是一个volatile变量，那么在多线程场景下，我们是不是直接把所有Segment的count相加就可以得到整个ConcurrentHashMap大小了呢？</p>
<p>不是的，虽然相加时可以获取每个Segment的count的最新值，但是拿到之后可能累加前使用的count发生了变化，那么统计结果就不准了。</p>
<p>所以最安全的做法，是在统计size的时候把所有Segment的put，remove和clean方法全部锁住，但是这种做法显然非常低效。 因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是<strong>先尝试2次通过不锁住Segment的方式来统计各个Segment大小</strong>，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。</p>
<p>那么ConcurrentHashMap是如何判断在统计的时候容器是否发生了变化呢？</p>
<p>使用modCount变量，在put , remove和clean方法里操作元素前都会将变量modCount进行加1，那么在统计size前后比较modCount是否发生变化，从而得知容器的大小是否发生变化。</p>
<pre><code>public int size() {
    final Segment&lt;K,V&gt;[] segments = this.segments;
    long sum = 0;
    long check = 0;
    int[] mc = new int[segments.length];
    // Try a few times to get accurate count. On failure due to
    // continuous async changes in table, resort to locking.
    // RETRIES_BEFORE_LOCK 的值为2.
    for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) {
        check = 0;//用来记录是否在检验累加过程中修改次数发生了改变
        sum = 0;//用来统计总长度
        int mcsum = 0; //用来统计各个 Segment 被修改的次数之和
        for (int i = 0; i &lt; segments.length; ++i) {
            sum += segments[i].count;
            mcsum += mc[i] = segments[i].modCount;
        }
        if (mcsum != 0) {
            for (int i = 0; i &lt; segments.length; ++i) {
                check += segments[i].count;
                if (mc[i] != segments[i].modCount) {
                    check = -1; // force retry
                    break;
                }
            }
        }
        if (check == sum)
            break;
    }
    if (check != sum) { // 如果发生了改变，则将每一个Segment 都锁住，然后进行累加。
        sum = 0;
        for (int i = 0; i &lt; segments.length; ++i)
            segments[i].lock();
        for (int i = 0; i &lt; segments.length; ++i)
            sum += segments[i].count;
        for (int i = 0; i &lt; segments.length; ++i)
            segments[i].unlock();
    }
    if (sum &gt; Integer.MAX_VALUE)
        return Integer.MAX_VALUE;
    else
        return (int)sum;
}
</code></pre><h2 id="Segment-的实现"><a href="#Segment-的实现" class="headerlink" title="Segment 的实现"></a>Segment 的实现</h2><p>Segment 只是 ConcurrentHashMap 内部的一个静态类。</p>
<pre><code>public class ConcurrentHashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt;  
    implements ConcurrentMap&lt;K, V&gt;, Serializable {  


    /** 
     *  key, hash, next都是不可改的 
       *  value值可被重写 
       */  
    static final class HashEntry&lt;K,V&gt; {  
        final K key;  
        final int hash;  
        volatile V value;  
        final HashEntry&lt;K,V&gt; next;  

        ...  
    }  

    static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {  

    transient volatile int count;  
    transient volatile HashEntry[] table;  
    // 当segment中元素个数达到threshold时，需要rehash  
    transient int threshold;  
    }  

      ...  
}   
</code></pre><h3 id="Segment-的-get-操作"><a href="#Segment-的-get-操作" class="headerlink" title="Segment 的 get 操作"></a>Segment 的 get 操作</h3><pre><code> V get(Object key, int hash) {
    if (count != 0) { // read-volatile
        HashEntry&lt;K,V&gt; e = getFirst(hash);
        while (e != null) {
            if (e.hash == hash &amp;&amp; key.equals(e.key)) {
                V v = e.value;
                if (v != null)
                    return v;
                return readValueUnderLock(e); // recheck
            }
            e = e.next;
        }
    }
    return null;
}
</code></pre><p>下面是getFirst的代码：</p>
<pre><code> HashEntry&lt;K,V&gt; getFirst(int hash) {
    HashEntry&lt;K,V&gt;[] tab = table;
    return tab[hash &amp; (tab.length - 1)];
}
</code></pre><p>由于HashEntry当中的key和next都是final的，所以segment之上的操作不可能影响HashEntry列表之间相对的顺序，而value是可变的，当第一次读值失败时，尝试加锁读。</p>
<p>以上源代码都是 JDK 1.6 版本的。</p>
<h3 id="Segment-的-put-操作"><a href="#Segment-的-put-操作" class="headerlink" title="Segment 的 put 操作"></a>Segment 的 put 操作</h3><pre><code>V put(K key, int hash, V value, boolean onlyIfAbsent) {
    lock();
    try {
        int c = count;
        if (c++ &gt; threshold) // ensure capacity
            rehash(); //扩容
        HashEntry&lt;K,V&gt;[] tab = table;
        int index = hash &amp; (tab.length - 1);
        HashEntry&lt;K,V&gt; first = tab[index]; // 用 first 指向下标为 index 的链表的第一个元素
        HashEntry&lt;K,V&gt; e = first;//e作为一个指针指向链表头，开始遍历
        while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) //必须 hash 和 key 都相等才满足条件
            e = e.next;

        V oldValue;
        if (e != null) { //找到了一样的元素
            oldValue = e.value; //替换旧值，注意这里没有修改 modCount 的值
            if (!onlyIfAbsent)
                e.value = value;
        }
        else { //一直找到链表结尾
            oldValue = null;
            ++modCount; //修改次数增加
            tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value);//因为每一个 HashEntry 的 next 指针都不能修改，所以只能插到链表头
            count = c; // write-volatile
        }
        return oldValue;
    } finally {
        unlock();
    }
}
</code></pre><p>当数量达到了 threadhold 时，用到了 rehash 函数。其源码如下：</p>
<pre><code>void rehash() { //扩容
    HashEntry&lt;K,V&gt;[] oldTable = table;
    int oldCapacity = oldTable.length;
    if (oldCapacity &gt;= MAXIMUM_CAPACITY)
        return;
    HashEntry&lt;K,V&gt;[] newTable = HashEntry.newArray(oldCapacity&lt;&lt;1);//扩大2倍
    threshold = (int)(newTable.length * loadFactor); //新的 threshhold
    int sizeMask = newTable.length - 1;
    for (int i = 0; i &lt; oldCapacity ; i++) {
        HashEntry&lt;K,V&gt; e = oldTable[i];
        if (e != null) {
            HashEntry&lt;K,V&gt; next = e.next;
            int idx = e.hash &amp; sizeMask; //计算节点所在数组的新的下标

            // 链表上只有一个节点
            if (next == null)
                newTable[idx] = e;
            //链表上不止一个节点
            else {
                // Reuse trailing consecutive sequence at same slot
                HashEntry&lt;K,V&gt; lastRun = e;
                int lastIdx = idx;
                for (HashEntry&lt;K,V&gt; last = next;
                     last != null;
                     last = last.next) {
                    int k = last.hash &amp; sizeMask;
                    if (k != lastIdx) {
                        lastIdx = k;
                        lastRun = last;
                    }
                }
                newTable[lastIdx] = lastRun;//挂到新的下标上

                // 复制链表上剩余的节点
                for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) {
                    int k = p.hash &amp; sizeMask;
                    HashEntry&lt;K,V&gt; n = newTable[k];
                    newTable[k] = new HashEntry&lt;K,V&gt;(p.key, p.hash,
                                                     n, p.value);
                }
            }
        }
    }
    table = newTable;
}
</code></pre><p>因为 HashEntry 的 next 属性是 final ，所以不能改变其指针的指向，只能对原来的链表进行复制。有统计规律指出，其实需要移动到新的下标上的元素只有 1/6.所以上面那一段代码对于性能的改善还是很重要的。</p>
</div></article></div><div class="right-container"><div class="widget"><div id="arAnchorBar"></div></div></div></section></div><div class="right-menu"></div><div class="modal search-modal"><div class="input-field"><input type="text" id="search_input"><label for="search-input">搜索</label></div><div id="search_result" class="search-result"></div></div><div class="blog-overlay"></div><footer class="row"><div class="footer-con"><div class="paginator"><a href="/2015/08/17/java-util-concurrent-locks-包/" title="java.util.concurrent.locks 包" class="prev">上一篇</a><a href="/2015/07/30/Struts-源码学习之运行主线/" title="Struts 源码学习之运行主线" class="next">下一篇</a></div><a href="#comment" class="comment-anchor"></a><div id="vcomments"></div><script>new Valine({
    el: "#vcomments",
    appId: "aD8jJBpu4oew3ovNY73z6Rdq-gzGzoHsz",
    appKey: "FdzS5SOPHdhYQoEUngQ8K2QW",
    notify: false,
    verify: false,
    avatar: "robohash",
    visitor: true,
    placeholder: "随便说点什么～.～",
});</script><div class="copyright"><p>© 2016 - 2019 <a target="_blank">Leexuehan</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <br> and <a href="https://github.com/Bulandent/hexo-theme-bubuzou" target="_blank">hexo-theme-bubuzou</a></p><p> <span style="padding-right: 6px;">闽ICP备16007301号-2</span></p></div><div class="totop"><i></i></div></div></footer><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="/scripts/jquery-1.8.2.min.js"></script><script src="/scripts/ar-anchor.js"></script><script src="/scripts/main.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script><script>const valineAPI = (() => {
try {
    AV.init("aD8jJBpu4oew3ovNY73z6Rdq-gzGzoHsz", "FdzS5SOPHdhYQoEUngQ8K2QW");
} catch(error) {}
const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
    query.equalTo("identity", identity);
    query.find().then(results => {
        resolve(results.length > 0);
    }, error => reject(error));
    })
}

const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
    let querys = [];
    for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
    }
    query = AV.Query.or.apply(null ,querys);
    } else {
    identity = identity || getRealPath();
    query = new AV.Query("Timer");
    query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
    query.find()
    .then(results => resolve(results))
    .catch(error => reject(error))
    })
}

const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let Todo = AV.Object.extend('Timer');
    let todo = new Todo();
    todo.set("times", 1);
    todo.set("identity", identity);
    todo.save().then(res => resolve(true), error => reject(error));
    })
}

const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let query = new AV.Query('Timer');
    query.equalTo("identity", identity);
    query.find().then(todos => {
        todos.forEach(todo => {
        todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
    }).then(todos => resolve(true), error => reject(error));
    })
}

return {
    isExist,
    _get,
    update,
    create
}
})()

const calcAndWriteTimes = () => {
let isPost = true;

let timerAllDOM = document.querySelectorAll(".article-timer");

if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
    if(exist) {
        return valineAPI.update(identity);
    }
    return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
}

let timerDOMCache = {};

for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
    timerDOMCache[identity].dom.push(timerDOM);
    }else{
    timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
    };
    }
}

let identities = Object.keys(timerDOMCache);
valineAPI._get(identities).then(results => {
    for(let result of results) {
    let {identity, times} = result.attributes;
    timerDOMCache[identity].times = times;
    timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
    if(timerDOMCache[identity].times){
        continue;
    }
    timerDOMCache[identity].dom.map(item => item.innerText = 1);
    valineAPI.create(identity);
    }
}).catch(error => console.log(error.message))
}

if(true){
calcAndWriteTimes();
}</script></body></html>