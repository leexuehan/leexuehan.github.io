<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="1EB8XoOl0C"><meta name="google-site-verification" content="K7thEgdLm0UfRWJ5MGdF7sCcjClSzAlxFLPv2Oz5CGM"><title> KafkaConsumer之Rebalance · 以梦为码的博客</title><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="KafkaConsumer之Rebalance - Leexuehan"><meta name="keywords"><meta name="author" content="Leexuehan"><link rel="short icon" href="/images/favicon.ico"><link rel="stylesheet" href="/css/bubuzou.css"><link rel="search" type="application/opensearchdescription+xml" href="https://leexuehan.github.io/atom.xml" title="以梦为码的博客"><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script></head><body><header><div class="header row"> <a href="/" class="logo-link"><img src="/images/logo.png"></a><ul id="nav_list" class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" data-hover="博文" class="nav-list-link">博文</a></li><li class="nav-list-item"><a href="/archives/" target="_self" data-hover="归档" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/categories/闲聊/" target="_self" data-hover="生活" class="nav-list-link">生活</a></li><li class="nav-list-item"><a href="/categories/技术/" target="_self" data-hover="技术" class="nav-list-link">技术</a></li><li class="nav-list-item"><a href="/about/" target="_self" data-hover="关于" class="nav-list-link">关于</a></li></ul><div class="search"><a id="search_btn" href="#search"></a></div><div id="nav_btn" class="nav-btn"><span></span><span></span><span></span></div></div></header><div class="row scroll-con"><section class="container"><!-- for archive page--><div id="postAr" class="post"><article class="post-block"><h1 class="post-title">KafkaConsumer之Rebalance</h1><div class="post-info">2019-08-15<p class="visit"><i data-identity="2019/08/15/KafkaConsumer之Rebalance/" class="article-timer"></i><span>次访问</span></p></div><div class="post-content"><p>本文主要就 Kafka 的消费者端的分区分配策略进行简单探讨。</p>
<a id="more"></a>
<h2 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h2><p>分组订阅机制算是 Kafka 消息引擎的一大特点了。</p>
<p>简言之，就是消费者与消费者可以组成一个 Group 去消费一个 Topic 的消息。</p>
<p>其示意图如下。</p>
<p><div align="center"><img src="./consumer.png" alt="consumer"></div></p>
<p>从图中可以看出：生产者将消息发送到指定 Topic 的 Partition 之后，消费者会以<strong>组</strong>为单位，对每个 Partition 进行消费，也就是说：<strong>每个 Partition 中的消息必然会到达每个消费者组</strong>。</p>
<p>上图中会产生一个疑问：Consumer Group1 中有两个消费者： Consumer1 和 Consumer2。而 Partition1到Partition4的消息都会到达这个组。这样会产生一个现象：<code>2</code> 个消费者消费 <code>4</code> 个 Partition 中的消息。</p>
<p>那么它们的分配方式是什么呢？分区策略又是在哪里执行的呢，是 Kafka Consumer 端还是 Kafka Broker 端呢？</p>
<p>先回答第一个问题：Kafka 的分区策略主要分为两种：Range 和 RoundRobin。</p>
<h3 id="Range"><a href="#Range" class="headerlink" title="Range"></a>Range</h3><p>Range 策略的执行步骤如下：</p>
<ol>
<li><p>对同一 Topic 下的 Partition 按照序号进行排序，以上图为例，则排好序的分区序号依次为：0、1、2、3.</p>
</li>
<li><p>对 Group 里面的消费者也按照序号排序，以上图为例，则排好序的消费者序号依次为：0、1。</p>
</li>
<li><p>Consumer的个数为 2，Partition 的个数为 4，所以按照算法 4/2 = 2，每个消费者消费 2 个 Partition。注意是连续的两个 Partition： Consumer0 消费 Partition-0 和 Partition-1，Consumer1 消费 Partition-2 和 Partition-3.</p>
<p>【注】：如果不能整除怎么办？答：还是顺序消费，多出来的 Partition 会从头开始顺延派发。假如 Partition 的个数为 5， Consumer 的个数为 2， 则 Consumer0 会消费 Partition：0、1、2，Consumer1会消费 Partition：3、4。以此类推。</p>
</li>
</ol>
<h3 id="RoundRobin"><a href="#RoundRobin" class="headerlink" title="RoundRobin"></a>RoundRobin</h3><p>将所有的分区组成TopicAndPartition 列表，然后依照 hashcode 进行排序。以上图为例，假如排好序的 TopicAndPartition 列表如下：</p>
<p>T-3</p>
<p>T-1                    </p>
<p>T-2</p>
<p>T-0</p>
<p>则 Consumer0 会消费 T-3 和 T-2，Consumer1 会消费 T-1 和 T-0。</p>
<p>与 Range 消费连续 Partition 不同， RoundRobin 采用类似“等间隔采样”的思想。</p>
<h3 id="指定-Partition"><a href="#指定-Partition" class="headerlink" title="指定 Partition"></a>指定 Partition</h3><p>除了以上两种策略外，在 Consumer 端可以<strong>消费指定的</strong> Partition。但是注意：目前还不能指定 Partition 的分配策略。</p>
<p>以上解答了第一个问题：Partition 与 Consumer 的分配关系。</p>
<p>第二个问题：Partition 策略在哪儿实现的？是在服务端完成的还是客户端完成的？</p>
<p>这就涉及到了 Rebalance 机制。</p>
<h2 id="Rebalance-机制"><a href="#Rebalance-机制" class="headerlink" title="Rebalance 机制"></a>Rebalance 机制</h2><p>关于 Rebalance 机制，Kafka 的设计先后经历了三种方案。</p>
<h3 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h3><p>方案一是采用在 zookeeper 上添加 Watcher 来实现的，如图。</p>
<p><div align="center"><img src="./zookeeper.png" alt="zookeeper"></div></p>
<ul>
<li>/brokers/ids/broker 记录了host、port 以及在此 broker 上的 topic 分区列表</li>
<li>/broker/topics/[topic_name] 记录了每个Partition的Leader和 ISR 信息</li>
<li>/consumer/group_id/ids 记录了消费者的信息</li>
<li>/consumer/group_id/offsets 记录了 consumer group 在某个 partition 上的消费位置</li>
<li>/consumer/group_id/owners 记录了 partition 与 consumer 的对应关系。</li>
</ul>
<p>可以看出来，<strong>消费者通过监听 zookeeper 路径下的变化便可感知到消费者组的变化情况</strong>。</p>
<p>但是这个方案有两个问题：</p>
<ol>
<li><p>“羊群效应”</p>
<p>任何 consumer 或者 broker  的加入都会触发 Watcher 通知 consumer，导致大量的通知被发送给客户端。</p>
</li>
<li><p>脑裂问题</p>
<p>由于 zookeeper 只保证最终一致性。所以当不同的 consumer 连接不同的 zookeeper 节点的时候，会造成短时间内看到的元数据不一样，引起不正确的 Rebalance 尝试。</p>
</li>
</ol>
<h3 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h3><p>针对方案一中的两个问题，方案二分别作出了改进。</p>
<p>原来的羊群效应是因为发送的通知太多，在方案二里引入了一个代理，代理监听 zookeeper 节点的变化，节点变化后只要通知代理即可，这个代理就是 GroupCoordinator。</p>
<p>在本方案里，所有的 Consumer 组被划分成为几个子集，每个子集由一个 GroupCoordinator 代理。</p>
<p>此时就变成了：Consumer 依赖 GroupCoordinator， GroupCoordinator 依赖 zookeeper。</p>
<p><strong>Consumer 加入或者退出 Group 时，还是会修改 Zookeeper 上保存的元数据，但是此时 zookeeper 只发送通知给 GroupCoordinator，由 GroupCoordinator 进行 Rebalance 操作。</strong></p>
<p>下面简单图示出来，一个 Consumer 加入一个 Group 的过程：</p>
<p><div align="center"><img src="./JoinGroup.png" alt="JoinGroup"></div></p>
<ol>
<li>Consumer 向 Kafka Broker 集群中的任一节点<strong>获取元数据</strong>请求，请求中包含了自身所在的 GroupId，节点收到请求之后，返回的响应中就包含了 GroupCoordinator  的信息；</li>
<li>Consumer 向 GroupCoordinator  周期性发送 HeartbeatRequest 请求，目的是告诉 GroupCoordinator 自己正常在线。</li>
<li>GroupCoordinator 通过在 HeartbeatResponse 中封装 IllegalGeneration 异常告诉 Consumer，发起Rebalance 操作；</li>
<li>Consumer 向 GroupCoordinator 发送 JoinGroupRequest <strong>加入 Group </strong>。</li>
<li>GroupCoordinator 根据 zookeeper 存储的元数据信息和请求制定分配方案，并将方案写入 zookeeper 中</li>
<li>GroupCoordinator 将制定好的分区分配方案写入 JoinGroupResponse 中，返回到 Consumer 。</li>
<li>Consumer 解析收到的响应中包含的 GroupCoordinator 已经制定好的分区方案，按照分区开始消费</li>
<li>继续执行步骤 2.</li>
</ol>
<p>方案的时序图如下所示：</p>
<p><div align="center"><img src="./Solution2.png" alt="方案二执行时序图"></div></p>
<p>但是此方案也有其缺点： 分区策略由服务端的 GroupCoordinator  来制定，一旦需要更改分区策略，就得重启服务器，不太灵活。</p>
<h3 id="方案三"><a href="#方案三" class="headerlink" title="方案三"></a>方案三</h3><p>针对方案二由服务器端制定分区分配方案这一不灵活的缺陷，方案三改为由 Consumer 端制定分区分配方案。</p>
<p>大体来说，Consumer 加入一个组总共分为两阶段：JoinGroup 阶段和 Synchronizing Group State 阶段。</p>
<h4 id="JoinGroup-阶段"><a href="#JoinGroup-阶段" class="headerlink" title="JoinGroup 阶段"></a>JoinGroup 阶段</h4><p>当 Consumer 请求加入组时，它会向 GroupCoordinator  发送 JoinGroup 请求，在该请求中包含了 Consumer 订阅的 Topic。</p>
<p>收集好全部成员的 JoinGroup 请求之后，GroupCoordinator  会从这些 Consumer 中选择一个担任这个 Group 的 Leader。</p>
<p>通常情况下：第一个发送 JoinGroup 请求的会自动称为 Group Leader。</p>
<p>选出来 Leader 之后，GroupCoordinator   会将 Consumer 的全部订阅信息封装到 JoinGroup 响应中，发送给 Group Leader，由 Group Leader 制定分区方案；其它 Consumer 也会收到 JoinGroup 响应，但是响应中没有订阅信息。</p>
<p>此时进入下一个阶段。</p>
<h4 id="Synchronizing-Group-State-阶段"><a href="#Synchronizing-Group-State-阶段" class="headerlink" title="Synchronizing Group State 阶段"></a>Synchronizing Group State 阶段</h4><p>在此阶段，Group Leader 向 GroupCoordinator 发送 SyncGroup 请求，请求中封装了制定好的分区方案；而其他 Consumer 发送的 SyncGroup 请求中并没有实际内容。</p>
<p>当 Group 内所有成员都成功接收到分配方案后，Consumer 即开始正常消费消息。</p>
<h4 id="典型场景"><a href="#典型场景" class="headerlink" title="典型场景"></a>典型场景</h4><p>下面从 Broker 端的角度开始分析几个主要的场景的流程：</p>
<p>场景一：新成员入组</p>
<p>组处于 stable 状态时，如果有新成员加入。</p>
<p><div align="center"><img src="./member_add.png" alt="新成员加入"></div></p>
<p>场景二：组成员主动离组</p>
<p>Consumer 实例所在的进程或者线程调用 close 方法主动通知 GroupCoordinator 它要退出。</p>
<p><div align="center"><img src="./member_leave.png" alt="主动离组"></div></p>
<p>场景三：组成员崩溃离组</p>
<p>Consumer 实例发生了严重故障，突然宕机导致离组。此时 GroupCoordinator 需要等待超时才能感知。</p>
<p><div align="center"><img src="./member_crush.png" alt="崩溃离组"></div></p>
<p>场景四：重平衡时协调者对组内成员提交位移的处理。</p>
<p>每个组内成员都会定期汇报位移给 GroupCoordinator ，当 Rebalance 开启时，GroupCoordinator 会给予成员一段缓冲时间，要求每个成员必须在这段时间快速上报自己的位移信息，然后开启正常 JoinGroup/SyncGroup 请求发送。</p>
<p><div align="center"><img src="./offset_commit.png" alt="提交位移"></div></p>
<h4 id="如何找到-GroupCoordinator"><a href="#如何找到-GroupCoordinator" class="headerlink" title="如何找到 GroupCoordinator"></a>如何找到 GroupCoordinator</h4><p>方案三中 Consumer 不再需要从 Broker 节点中获取 GroupCoordinator 所在的位置信息。每个 Consumer Group 都有其对应的 GroupCoordinator，但具体是由哪个 GroupCoordinator 负责与 group.id 的 hash 值有关，通过这个 <strong>abs(GroupId.hashCode()) % NumPartitions</strong> 来计算出一个值（其中，NumPartitions 是 <code>__consumer_offsets</code> 的 partition 数，默认是50个），这个值代表了 <code>__consumer_offsets</code> 的一个 partition，而这个 partition 的 leader 即为这个 Group 要交互的 GroupCoordinator 所在的节点。</p>
<h2 id="Rebalance-缺点"><a href="#Rebalance-缺点" class="headerlink" title="Rebalance 缺点"></a>Rebalance 缺点</h2><p>Rebalance 的缺点就在于消费者组内实例数多的情况下，会造成一次 Rebalance 比较耗时。而且 Rebalance 时，所有的 Consumer 需要放下正在进行的消费工作，等待分配方案分配完成。</p>
<p>所以针对此，最好的优化就是：尽量避免 Rebalance 的发生。</p>
<p>（全文完）</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>《Apache Kafka 源码剖析》徐郡明</li>
<li>《Kafka核心技术与实战》胡夕</li>
<li><a href="https://www.iteblog.com/archives/2209.html" target="_blank" rel="noopener">https://www.iteblog.com/archives/2209.html</a></li>
</ol>
</div></article></div><div class="right-container"><div class="widget"><div id="arAnchorBar"></div></div></div></section></div><div class="right-menu"></div><div class="modal search-modal"><div class="input-field"><input type="text" id="search_input"><label for="search-input">搜索</label></div><div id="search_result" class="search-result"></div></div><div class="blog-overlay"></div><footer class="row"><div class="footer-con"><div class="paginator"><a href="/2019/08/03/Netty之异步机制/" title="Netty之异步机制" class="next">NEXT</a></div><a href="#comment" class="comment-anchor"></a><div id="vcomments"></div><script>new Valine({
    el: "#vcomments",
    appId: "aD8jJBpu4oew3ovNY73z6Rdq-gzGzoHsz",
    appKey: "FdzS5SOPHdhYQoEUngQ8K2QW",
    notify: false,
    verify: false,
    avatar: "robohash",
    visitor: true,
    placeholder: "随便说点什么～.～",
});</script><div class="copyright"><p>© 2016 - 2019 <a target="_blank">Leexuehan</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <br> and <a href="https://github.com/Bulandent/hexo-theme-bubuzou" target="_blank">hexo-theme-bubuzou</a></p><p> <span style="padding-right: 6px;">闽ICP备16007301号-2</span></p></div><div class="totop"><i></i></div></div></footer><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="/scripts/jquery-1.8.2.min.js"></script><script src="/scripts/ar-anchor.js"></script><script src="/scripts/main.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script><script>const valineAPI = (() => {
try {
    AV.init("aD8jJBpu4oew3ovNY73z6Rdq-gzGzoHsz", "FdzS5SOPHdhYQoEUngQ8K2QW");
} catch(error) {}
const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
    query.equalTo("identity", identity);
    query.find().then(results => {
        resolve(results.length > 0);
    }, error => reject(error));
    })
}

const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
    let querys = [];
    for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
    }
    query = AV.Query.or.apply(null ,querys);
    } else {
    identity = identity || getRealPath();
    query = new AV.Query("Timer");
    query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
    query.find()
    .then(results => resolve(results))
    .catch(error => reject(error))
    })
}

const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let Todo = AV.Object.extend('Timer');
    let todo = new Todo();
    todo.set("times", 1);
    todo.set("identity", identity);
    todo.save().then(res => resolve(true), error => reject(error));
    })
}

const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let query = new AV.Query('Timer');
    query.equalTo("identity", identity);
    query.find().then(todos => {
        todos.forEach(todo => {
        todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
    }).then(todos => resolve(true), error => reject(error));
    })
}

return {
    isExist,
    _get,
    update,
    create
}
})()

const calcAndWriteTimes = () => {
let isPost = true;

let timerAllDOM = document.querySelectorAll(".article-timer");

if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
    if(exist) {
        return valineAPI.update(identity);
    }
    return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
}

let timerDOMCache = {};

for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
    timerDOMCache[identity].dom.push(timerDOM);
    }else{
    timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
    };
    }
}

let identities = Object.keys(timerDOMCache);
valineAPI._get(identities).then(results => {
    for(let result of results) {
    let {identity, times} = result.attributes;
    timerDOMCache[identity].times = times;
    timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
    if(timerDOMCache[identity].times){
        continue;
    }
    timerDOMCache[identity].dom.map(item => item.innerText = 1);
    valineAPI.create(identity);
    }
}).catch(error => console.log(error.message))
}

if(true){
calcAndWriteTimes();
}</script></body></html>