<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="1EB8XoOl0C"><meta name="google-site-verification" content="K7thEgdLm0UfRWJ5MGdF7sCcjClSzAlxFLPv2Oz5CGM"><title> MySQL之 redo log · 以梦为码的博客</title><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="MySQL之 redo log - Leexuehan"><meta name="keywords"><meta name="author" content="Leexuehan"><link rel="short icon" href="/images/favicon.ico"><link rel="stylesheet" href="/css/bubuzou.css"><link rel="search" type="application/opensearchdescription+xml" href="https://leexuehan.github.io/atom.xml" title="以梦为码的博客"><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script></head><body><header><div class="header row"> <a href="/" class="logo-link"><img src="/images/logo.png"></a><ul id="nav_list" class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" data-hover="博文" class="nav-list-link">博文</a></li><li class="nav-list-item"><a href="/archives/" target="_self" data-hover="归档" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/categories/闲聊/" target="_self" data-hover="生活" class="nav-list-link">生活</a></li><li class="nav-list-item"><a href="/categories/技术/" target="_self" data-hover="技术" class="nav-list-link">技术</a></li><li class="nav-list-item"><a href="/about/" target="_self" data-hover="关于" class="nav-list-link">关于</a></li></ul><div class="search"><a id="search_btn" href="#search"></a></div><div id="nav_btn" class="nav-btn"><span></span><span></span><span></span></div></div></header><div class="row scroll-con"><section class="container"><!-- for archive page--><div id="postAr" class="post"><article class="post-block"><h1 class="post-title">MySQL之 redo log</h1><div class="post-info">2019-08-21<p class="visit"><i data-identity="2019/08/21/MySQL之-redo-log/" class="article-timer"></i><span>次访问</span></p></div><div class="post-content"><h1 id="Redo-log"><a href="#Redo-log" class="headerlink" title="Redo log"></a>Redo log</h1><h2 id="存储格式"><a href="#存储格式" class="headerlink" title="存储格式"></a>存储格式</h2><h3 id="block"><a href="#block" class="headerlink" title="block"></a>block</h3><p>redo log 包含两部分：一、内存中的日志缓冲（redo log buffer）；二、磁盘上的重做文件（redo log file）。</p>
<p>在 InnoDB 引擎中，redo log 以块作为单位进行存储，这样的块叫做 redo log block，每个块占用 512 byte。不管是 redo log buffer 还是 redo log file，都是以这样的方式进行存储的。</p>
<p>每个 redo log block 由三部分组成：日志块头（12 byte）、日志块尾（8 byte）和日志主体（492 byte），如图所示。</p>
<p><div align="center"><img src="./logblock" alt="log block"></div></p>
<p>其中，log block header 又包括四部分：</p>
<ul>
<li><p>LOG_BLOCK_HDR_NO</p>
<p>在 redo log buffer 中的位置 ID。</p>
</li>
<li><p>LOG_BLOCK_HDR_DATA_LEN</p>
<p>已经记录的 log 大小。</p>
</li>
<li><p>LOG_BLOCK_FIRST_REC_GROUP</p>
<p>第一个 log 的开始偏移位置。</p>
<p>此处需要解释一下：因为有时候一个数据页产生的日志量超出了一个日志块，所以只能用多个日志块来记录该页的相关日志。例如，某一数据页产生了<code>552</code>字节的日志量，那么需要占用两个日志块，第一个日志块占用<code>492</code>字节，第二个日志块需要占用<code>60</code>个字节，那么对于第二个日志块来说，它的第一个log的开始位置就是<code>73</code>字节(60字节内容+12字节头部)。</p>
</li>
<li><p>LOG_BLOCK_CHECKPOINT_NO</p>
<p>写入检查点的信息</p>
</li>
</ul>
<p>redo log  buffer 或者 redo log file  由很多 block 组成，如图：</p>
<p><div align="center"><img src="./manyblock" alt="manyblock"></div></p>
<p>log group 表示的是 redo log group，一个组内由多个大小完全相同的redo log file组成。组内 redo log file 的数量由变量 <code>innodb_log_files_group</code> 决定，默认值为 2，即两个 redo log file。<strong>group 是一个逻辑上的概念</strong>。</p>
<p>可以通过下面的命令行进行查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &quot;innodb_log%&quot;;</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| Variable_name               | Value    |</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| innodb_log_buffer_size      | 8388608  |</span><br><span class="line">| innodb_log_compressed_pages | ON       |</span><br><span class="line">| innodb_log_file_size        | 50331648 |</span><br><span class="line">| innodb_log_files_in_group   | 2        |</span><br><span class="line">| innodb_log_group_home_dir   | ./       |</span><br><span class="line">+-----------------------------+----------+</span><br></pre></td></tr></table></figure>
<p>可以看到，结果中显示了相关详细信息，包括 buffer 大小，log_file 的大小，log_file 的数量以及 log file 存放的目录。</p>
<p>进入目录后我们可以看到文件的命名为 ib_logfile0、ib_logfile1…。</p>
<p>InnoDB 存储引擎将 log buffer 中的 block 刷到这些 log_file 中时，会以追加循环的方式进行。</p>
<h3 id="page"><a href="#page" class="headerlink" title="page"></a>page</h3><p>因为 InnoDB 存储引擎中的数据存储单元是 page，所以 redo log 也是基于页进行存储的。默认情况下，InnoDB 页的大小是 16KB。每一个 Page 是由多个 Block 组成的。</p>
<h2 id="更新流程"><a href="#更新流程" class="headerlink" title="更新流程"></a>更新流程</h2><h3 id="脏日志（dirty-log）"><a href="#脏日志（dirty-log）" class="headerlink" title="脏日志（dirty log）"></a>脏日志（dirty log）</h3><p>前面提到，redo log 是由在内存中存在的部分（redo log buffer）和磁盘上存在的部分（redo log file）组成。所以，在更新 redo log 的时候，必然是先更新 redo log buffer，然后同步到 redo log file 进行持久化保存。</p>
<p><div align="center"><img src="./flush_structure.png" alt="更新层次"></div></p>
<p>从上图可以看出来：在写入事务日志文件时，会先从用户空间的 redo log buffer更新到内核空间中的 OS Buffer 中，然后经过系统调用 fsync，最终刷入磁盘的 log file 中。</p>
<p>当然，每次事务的提交并非一定会刷到磁盘的 log file 中，更新方式可以通过更改变量 <code>innodb_flush_log_at_trx_commit</code> 的值进行控制：</p>
<ul>
<li>该值为<code>1</code>时，事务每次提交都会立即将 log buffer 中的日志写入 os buffer 中，并调用 fsync 刷到磁盘的 log file</li>
<li>该值为<code>0</code>时，事务提交时不会立即将 log buffer中日志写入到 os buffer，而是每秒定时写入 os buffer，然后持久化到磁盘中。</li>
<li>该值为<code>2</code>时，事务每次提交都仅写入 os buffer，然后每秒定时从 os buffer 持久化到磁盘中。</li>
</ul>
<p><div align="center"><img src="./flush_level.png" alt="刷盘级别"></div></p>
<p>log buffer 中没有持久化到磁盘中的日志称为<strong>脏日志（dirty log）</strong>。</p>
<p>日志刷盘的有以下几种规则：</p>
<ol>
<li>发出 commit 动作时。由参数 <strong>innodb_flush_log_at_trx_commit</strong>  控制。</li>
<li>每秒刷一次。刷盘频率由 <strong>innodb_flush_log_at_timeout</strong> 值决定，默认为 1 秒。</li>
<li>当log buffer中已经使用的内存超过一半时。</li>
<li>当 checkpoint 需要往前推进时。</li>
</ol>
<h3 id="脏数据（dirty-data）"><a href="#脏数据（dirty-data）" class="headerlink" title="脏数据（dirty data）"></a>脏数据（dirty data）</h3><p>buffer pool 中未刷到磁盘中的数据称为<strong>脏数据（dirty data）</strong>。</p>
<p>前面提到日志刷盘有4条规则，而数据刷盘只有一条规则：checkpoint 触发刷数据。</p>
<p>在 InnoDB 存储引擎中，checkpoint 分为以下两种：</p>
<ol>
<li><p>sharp checkpoint</p>
<p>在重用 redo log 文件时，会将所有已经记录的redo log中对应的脏数据刷到磁盘。</p>
</li>
<li><p>fuzzy checkpoint</p>
<p>一次只刷一小部分的日志到磁盘，而非将所有的脏日志刷盘。</p>
</li>
</ol>
<h2 id="与-binlog-的区别"><a href="#与-binlog-的区别" class="headerlink" title="与 binlog 的区别"></a>与 binlog 的区别</h2><p>binlog 也称为二进制日志，记录了 InnoDB 表的很多操作，也能实现重做功能，但是他们之间还是有一些区别的：</p>
<ol>
<li><p>产生位置不同：</p>
<p>二进制日志是在 Server 层产生的，与存储引擎无关，只要对数据库进行修改就会产生二进制日志；</p>
<p>redo log 是在 InnoDB 存储引擎产生的，只记录存储引擎中表的修改。</p>
</li>
<li><p>二进制日志是<strong>逻辑性语句</strong>，如记录该行记录的每列的值是多少；redo log 是<strong>物理格式</strong>的日志，它记录的是数据库中每个页的修改。</p>
</li>
<li><p>提交方式不同：</p>
<p>二进制日志是一次写入的，而 redo log 是两阶段写入的。而且 redo log 会被滚动覆盖。</p>
</li>
<li><p>redo log 记录的是物理页的修改情况，具有幂等性（多次操作前后的状态时一直的）。</p>
</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://juejin.im/entry/5ba0a254e51d450e735e4a1f" target="_blank" rel="noopener">详细分析MySQL事务日志(redo log和undo log)</a></li>
</ol>
</div></article></div><div class="right-container"><div class="widget"><div id="arAnchorBar"></div></div></div></section></div><div class="right-menu"></div><div class="modal search-modal"><div class="input-field"><input type="text" id="search_input"><label for="search-input">搜索</label></div><div id="search_result" class="search-result"></div></div><div class="blog-overlay"></div><footer class="row"><div class="footer-con"><div class="paginator"><a href="/2019/08/22/JDK源码之ReentrantLock/" title="JDK源码之ReentrantLock" class="prev">PREV</a><a href="/2019/08/19/JDK源码之HashMap/" title="JDK源码之HashMap扩容" class="next">NEXT</a></div><a href="#comment" class="comment-anchor"></a><div id="vcomments"></div><script>new Valine({
    el: "#vcomments",
    appId: "aD8jJBpu4oew3ovNY73z6Rdq-gzGzoHsz",
    appKey: "FdzS5SOPHdhYQoEUngQ8K2QW",
    notify: false,
    verify: false,
    avatar: "robohash",
    visitor: true,
    placeholder: "随便说点什么～.～",
});</script><div class="copyright"><p>© 2016 - 2019 <a target="_blank">Leexuehan</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <br> and <a href="https://github.com/Bulandent/hexo-theme-bubuzou" target="_blank">hexo-theme-bubuzou</a></p><p> <span style="padding-right: 6px;">闽ICP备16007301号-2</span></p></div><div class="totop"><i></i></div></div></footer><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="/scripts/jquery-1.8.2.min.js"></script><script src="/scripts/ar-anchor.js"></script><script src="/scripts/main.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script><script>const valineAPI = (() => {
try {
    AV.init("aD8jJBpu4oew3ovNY73z6Rdq-gzGzoHsz", "FdzS5SOPHdhYQoEUngQ8K2QW");
} catch(error) {}
const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
    query.equalTo("identity", identity);
    query.find().then(results => {
        resolve(results.length > 0);
    }, error => reject(error));
    })
}

const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
    let querys = [];
    for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
    }
    query = AV.Query.or.apply(null ,querys);
    } else {
    identity = identity || getRealPath();
    query = new AV.Query("Timer");
    query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
    query.find()
    .then(results => resolve(results))
    .catch(error => reject(error))
    })
}

const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let Todo = AV.Object.extend('Timer');
    let todo = new Todo();
    todo.set("times", 1);
    todo.set("identity", identity);
    todo.save().then(res => resolve(true), error => reject(error));
    })
}

const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let query = new AV.Query('Timer');
    query.equalTo("identity", identity);
    query.find().then(todos => {
        todos.forEach(todo => {
        todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
    }).then(todos => resolve(true), error => reject(error));
    })
}

return {
    isExist,
    _get,
    update,
    create
}
})()

const calcAndWriteTimes = () => {
let isPost = true;

let timerAllDOM = document.querySelectorAll(".article-timer");

if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
    if(exist) {
        return valineAPI.update(identity);
    }
    return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
}

let timerDOMCache = {};

for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
    timerDOMCache[identity].dom.push(timerDOM);
    }else{
    timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
    };
    }
}

let identities = Object.keys(timerDOMCache);
valineAPI._get(identities).then(results => {
    for(let result of results) {
    let {identity, times} = result.attributes;
    timerDOMCache[identity].times = times;
    timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
    if(timerDOMCache[identity].times){
        continue;
    }
    timerDOMCache[identity].dom.map(item => item.innerText = 1);
    valineAPI.create(identity);
    }
}).catch(error => console.log(error.message))
}

if(true){
calcAndWriteTimes();
}</script></body></html>